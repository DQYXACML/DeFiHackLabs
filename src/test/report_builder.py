#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æŠ¥å‘Šç”Ÿæˆå™¨

åŠŸèƒ½ï¼š
- ç”ŸæˆMarkdownæ ¼å¼çš„äººç±»å¯è¯»æŠ¥å‘Š
- ç”ŸæˆJSONæ ¼å¼çš„æœºå™¨å¯è¯»æŠ¥å‘Š
- ç”ŸæˆCSVæ ¼å¼çš„æ±‡æ€»ç»Ÿè®¡
"""

import json
import logging
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
import csv

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ReportBuilder:
    """æŠ¥å‘Šæ„å»ºå™¨"""

    def __init__(
        self,
        event_name: str,
        year_month: str,
        output_dir: Path
    ):
        """
        åˆå§‹åŒ–æŠ¥å‘Šæ„å»ºå™¨

        Args:
            event_name: æ”»å‡»äº‹ä»¶åç§°
            year_month: å¹´æœˆç›®å½•
            output_dir: è¾“å‡ºç›®å½•
        """
        self.event_name = event_name
        self.year_month = year_month
        self.output_dir = output_dir

        # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def build_report(
        self,
        invariants: List[Dict],
        violation_results: List,
        storage_changes: Dict,
        runtime_metrics: Optional[Dict],
        attack_tx_hash: Optional[str] = None
    ):
        """
        ç”Ÿæˆå®Œæ•´æŠ¥å‘Š

        Args:
            invariants: ä¸å˜é‡åˆ—è¡¨
            violation_results: è¿è§„ç»“æœåˆ—è¡¨
            storage_changes: å­˜å‚¨å˜åŒ–
            runtime_metrics: è¿è¡Œæ—¶æŒ‡æ ‡
            attack_tx_hash: æ”»å‡»äº¤æ˜“hash
        """
        # ç”ŸæˆMarkdownæŠ¥å‘Š
        markdown_file = self.output_dir / f"{self.event_name}_dynamic_report.md"
        self._generate_markdown(
            markdown_file,
            invariants,
            violation_results,
            storage_changes,
            runtime_metrics,
            attack_tx_hash
        )

        # ç”ŸæˆJSONæŠ¥å‘Š
        json_file = self.output_dir / f"{self.event_name}_dynamic_report.json"
        self._generate_json(
            json_file,
            invariants,
            violation_results,
            storage_changes,
            runtime_metrics,
            attack_tx_hash
        )

        logger.info(f"æŠ¥å‘Šå·²ç”Ÿæˆ:")
        logger.info(f"  - Markdown: {markdown_file}")
        logger.info(f"  - JSON: {json_file}")

    def _generate_markdown(
        self,
        output_file: Path,
        invariants: List[Dict],
        violation_results: List,
        storage_changes: Dict,
        runtime_metrics: Optional[Dict],
        attack_tx_hash: Optional[str]
    ):
        """ç”ŸæˆMarkdownæŠ¥å‘Š"""
        violations = [r for r in violation_results if r.violated]
        passed = [r for r in violation_results if not r.violated]

        md_lines = []

        # æ ‡é¢˜
        md_lines.append(f"# åŠ¨æ€ä¸å˜é‡æ£€æµ‹æŠ¥å‘Š - {self.event_name}\n")
        md_lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        md_lines.append("---\n")

        # åŸºæœ¬ä¿¡æ¯
        md_lines.append("## ğŸ“‹ åŸºæœ¬ä¿¡æ¯\n")
        md_lines.append(f"- **æ”»å‡»åç§°**: {self.event_name}")
        md_lines.append(f"- **å¹´æœˆ**: {self.year_month}")
        if attack_tx_hash:
            md_lines.append(f"- **æ”»å‡»äº¤æ˜“**: `{attack_tx_hash}`")
        md_lines.append(f"- **æ£€æµ‹æ–¹æ³•**: åŠ¨æ€æ‰§è¡Œï¼ˆAnvilé‡æ”¾ï¼‰\n")

        # æ‰§è¡Œæ‘˜è¦
        md_lines.append("## ğŸ“Š æ‰§è¡Œæ‘˜è¦\n")
        md_lines.append(f"- **æ€»ä¸å˜é‡æ•°**: {len(violation_results)}")
        md_lines.append(f"- **è¿è§„æ•°é‡**: {len(violations)} âŒ")
        md_lines.append(f"- **é€šè¿‡æ•°é‡**: {len(passed)} âœ…")
        md_lines.append(f"- **è¿è§„ç‡**: {len(violations) / len(violation_results) * 100:.1f}%\n" if violation_results else "- **è¿è§„ç‡**: N/A\n")

        # è¿è¡Œæ—¶æŒ‡æ ‡
        if runtime_metrics:
            md_lines.append("## âš¡ è¿è¡Œæ—¶æŒ‡æ ‡\n")
            md_lines.append(f"- **Gasä½¿ç”¨**: {runtime_metrics.get('gas_used', 'N/A'):,}")
            md_lines.append(f"- **è°ƒç”¨æ·±åº¦**: {runtime_metrics.get('call_depth', 'N/A')}")
            md_lines.append(f"- **é‡å…¥æ·±åº¦**: {runtime_metrics.get('reentrancy_depth', 'N/A')}")
            md_lines.append(f"- **å¾ªç¯è¿­ä»£**: {runtime_metrics.get('loop_iterations', 'N/A')}")
            md_lines.append(f"- **æ± å­åˆ©ç”¨ç‡**: {runtime_metrics.get('pool_utilization', 'N/A')}%\n")

        # è¿è§„è¯¦æƒ…
        if violations:
            md_lines.append("## âŒ è¿è§„è¯¦æƒ…\n")

            for i, v in enumerate(violations, 1):
                md_lines.append(f"### {i}. [{v.invariant_id}] {v.invariant_type}\n")
                md_lines.append(f"**ä¸¥é‡ç¨‹åº¦**: `{v.severity.value.upper()}`\n")
                md_lines.append(f"**æè¿°**: {v.description}\n")
                md_lines.append(f"**é˜ˆå€¼**: `{v.threshold}`")
                md_lines.append(f"**å®é™…å€¼**: `{v.actual_value}` ğŸš¨\n")
                md_lines.append(f"**å½±å“**: {v.impact}\n")

                # è¯æ®
                md_lines.append("**è¯æ®**:")
                md_lines.append("```json")
                md_lines.append(json.dumps(v.evidence, indent=2))
                md_lines.append("```\n")
                md_lines.append("---\n")

        # é€šè¿‡çš„ä¸å˜é‡
        if passed:
            md_lines.append("## âœ… é€šè¿‡æ£€æµ‹çš„ä¸å˜é‡\n")

            for i, v in enumerate(passed, 1):
                md_lines.append(f"{i}. **[{v.invariant_id}]** {v.invariant_type} - {v.description}")
                md_lines.append(f"   - é˜ˆå€¼: `{v.threshold}`, å®é™…: `{v.actual_value}`\n")

        # å­˜å‚¨å˜åŒ–æ‘˜è¦
        md_lines.append("## ğŸ“¦ å­˜å‚¨å˜åŒ–æ‘˜è¦\n")

        if storage_changes:
            # ç»Ÿè®¡æœ‰å˜åŒ–çš„å­˜å‚¨æ§½æ•°é‡
            total_slots = sum(len(slots) for contract, slots in storage_changes.items()
                              if contract != 'balances')

            md_lines.append(f"- **å˜åŒ–çš„åˆçº¦æ•°**: {len([c for c in storage_changes.keys() if c != 'balances'])}")
            md_lines.append(f"- **å˜åŒ–çš„å­˜å‚¨æ§½æ•°**: {total_slots}")

            # æ˜¾ç¤ºæœ€å¤§å˜åŒ–
            max_changes = []
            for contract, slots in storage_changes.items():
                if contract == 'balances':
                    continue
                for slot, data in slots.items():
                    change_rate = data.get('change_rate', 0)
                    if change_rate > 0:
                        max_changes.append((contract, slot, change_rate, data))

            # æ’åºå¹¶æ˜¾ç¤ºå‰5
            max_changes.sort(key=lambda x: x[2], reverse=True)

            if max_changes:
                md_lines.append("\n**å˜åŒ–ç‡æœ€å¤§çš„å­˜å‚¨æ§½**:\n")
                for contract, slot, rate, data in max_changes[:5]:
                    md_lines.append(f"- `{contract[:10]}...` slot {slot}: "
                                    f"{data['before']} â†’ {data['after']} "
                                    f"(å˜åŒ– {data['change_pct']})")

        md_lines.append("\n---")
        md_lines.append(f"\n*æŠ¥å‘Šç”±åŠ¨æ€ä¸å˜é‡æ£€æµ‹å™¨è‡ªåŠ¨ç”Ÿæˆ*")

        # å†™å…¥æ–‡ä»¶
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(md_lines))

    def _generate_json(
        self,
        output_file: Path,
        invariants: List[Dict],
        violation_results: List,
        storage_changes: Dict,
        runtime_metrics: Optional[Dict],
        attack_tx_hash: Optional[str]
    ):
        """ç”ŸæˆJSONæŠ¥å‘Š"""
        violations = [r for r in violation_results if r.violated]

        report = {
            'report_metadata': {
                'event_name': self.event_name,
                'year_month': self.year_month,
                'generated_at': datetime.now().isoformat(),
                'detection_method': 'dynamic_execution',
                'attack_tx_hash': attack_tx_hash
            },
            'summary': {
                'total_invariants': len(violation_results),
                'violations_detected': len(violations),
                'passed': len(violation_results) - len(violations),
                'violation_rate': len(violations) / len(violation_results) if violation_results else 0
            },
            'runtime_metrics': runtime_metrics or {},
            'violation_results': [
                {
                    'invariant_id': r.invariant_id,
                    'invariant_type': r.invariant_type,
                    'severity': r.severity.value,
                    'violated': r.violated,
                    'threshold': str(r.threshold),
                    'actual_value': str(r.actual_value),
                    'description': r.description,
                    'impact': r.impact,
                    'evidence': r.evidence,
                    'confidence': r.confidence
                }
                for r in violation_results
            ],
            'storage_changes_summary': self._summarize_storage_changes(storage_changes)
        }

        with open(output_file, 'w') as f:
            json.dump(report, f, indent=2)

    def _summarize_storage_changes(self, storage_changes: Dict) -> Dict:
        """æ±‡æ€»å­˜å‚¨å˜åŒ–"""
        summary = {
            'total_contracts_changed': 0,
            'total_slots_changed': 0,
            'max_change_rate': 0,
            'top_changes': []
        }

        all_changes = []

        for contract, slots in storage_changes.items():
            if contract == 'balances':
                continue

            summary['total_contracts_changed'] += 1

            for slot, data in slots.items():
                summary['total_slots_changed'] += 1

                change_rate = data.get('change_rate', 0)
                if change_rate > summary['max_change_rate']:
                    summary['max_change_rate'] = change_rate

                all_changes.append({
                    'contract': contract,
                    'slot': slot,
                    'before': data['before'],
                    'after': data['after'],
                    'change_rate': change_rate,
                    'change_pct': data['change_pct']
                })

        # æŒ‰å˜åŒ–ç‡æ’åºï¼Œå–å‰10
        all_changes.sort(key=lambda x: x['change_rate'], reverse=True)
        summary['top_changes'] = all_changes[:10]

        return summary

    @staticmethod
    def generate_batch_summary(
        results: List[Dict],
        output_dir: Path
    ):
        """
        ç”Ÿæˆæ‰¹é‡æ£€æµ‹çš„æ±‡æ€»æŠ¥å‘Š

        Args:
            results: å„ä¸ªæ”»å‡»çš„æ£€æµ‹ç»“æœåˆ—è¡¨
            output_dir: è¾“å‡ºç›®å½•
        """
        # CSVæ±‡æ€»
        csv_file = output_dir / "batch_summary.csv"

        with open(csv_file, 'w', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([
                'æ”»å‡»åç§°',
                'å¹´æœˆ',
                'æ€»ä¸å˜é‡æ•°',
                'è¿è§„æ•°é‡',
                'é€šè¿‡æ•°é‡',
                'è¿è§„ç‡(%)',
                'çŠ¶æ€',
                'æ£€æµ‹æ—¶é—´'
            ])

            for result in results:
                writer.writerow([
                    result.get('event_name', ''),
                    result.get('year_month', ''),
                    result.get('total_invariants', 0),
                    result.get('violations', 0),
                    result.get('passed', 0),
                    f"{result.get('violation_rate', 0):.1f}",
                    result.get('status', 'Unknown'),
                    result.get('timestamp', '')
                ])

        # Markdownæ±‡æ€»
        md_file = output_dir / "batch_summary.md"

        md_lines = []
        md_lines.append("# æ‰¹é‡åŠ¨æ€æ£€æµ‹æ±‡æ€»æŠ¥å‘Š\n")
        md_lines.append(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        md_lines.append("---\n")

        # ç»Ÿè®¡
        total_attacks = len(results)
        successful = len([r for r in results if r.get('status') == 'Success'])
        failed = total_attacks - successful

        md_lines.append("## ğŸ“Š æ€»ä½“ç»Ÿè®¡\n")
        md_lines.append(f"- **æ€»æ”»å‡»æ•°**: {total_attacks}")
        md_lines.append(f"- **æˆåŠŸæ£€æµ‹**: {successful} âœ…")
        md_lines.append(f"- **æ£€æµ‹å¤±è´¥**: {failed} âŒ")
        md_lines.append(f"- **æˆåŠŸç‡**: {successful / total_attacks * 100:.1f}%\n" if total_attacks > 0 else "")

        # è¿è§„ç»Ÿè®¡
        total_violations = sum(r.get('violations', 0) for r in results)
        total_invariants = sum(r.get('total_invariants', 0) for r in results)

        md_lines.append("## ğŸ” è¿è§„ç»Ÿè®¡\n")
        md_lines.append(f"- **æ€»ä¸å˜é‡æ•°**: {total_invariants}")
        md_lines.append(f"- **æ€»è¿è§„æ•°**: {total_violations}")
        md_lines.append(f"- **æ€»ä½“è¿è§„ç‡**: {total_violations / total_invariants * 100:.1f}%\n" if total_invariants > 0 else "")

        # è¯¦ç»†åˆ—è¡¨
        md_lines.append("## ğŸ“‹ è¯¦ç»†ç»“æœ\n")
        md_lines.append("| æ”»å‡»åç§° | ä¸å˜é‡æ•° | è¿è§„æ•° | è¿è§„ç‡ | çŠ¶æ€ |")
        md_lines.append("|---------|---------|--------|-------|------|")

        for result in results:
            name = result.get('event_name', 'Unknown')
            total = result.get('total_invariants', 0)
            violations = result.get('violations', 0)
            rate = result.get('violation_rate', 0)
            status = "âœ…" if result.get('status') == 'Success' else "âŒ"

            md_lines.append(f"| {name} | {total} | {violations} | {rate:.1f}% | {status} |")

        md_lines.append("\n---")
        md_lines.append(f"\n*æ±‡æ€»æŠ¥å‘Šç”±æ‰¹é‡åŠ¨æ€æ£€æµ‹å™¨è‡ªåŠ¨ç”Ÿæˆ*")

        with open(md_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(md_lines))

        logger.info(f"æ‰¹é‡æ±‡æ€»æŠ¥å‘Šå·²ç”Ÿæˆ:")
        logger.info(f"  - CSV: {csv_file}")
        logger.info(f"  - Markdown: {md_file}")


if __name__ == '__main__':
    # æµ‹è¯•ç¤ºä¾‹
    from invariant_evaluator import ViolationResult, ViolationSeverity

    test_results = [
        ViolationResult(
            invariant_id='SINV_001',
            invariant_type='share_price_stability',
            severity=ViolationSeverity.CRITICAL,
            violated=True,
            threshold='5%',
            actual_value='87.3%',
            description='Vault share price must not change more than 5% per transaction',
            impact='Allows attacker to mint underpriced shares',
            evidence={'price_before': 5.0, 'price_after': 2.0}
        )
    ]

    builder = ReportBuilder(
        event_name='TestAttack',
        year_month='2024-01',
        output_dir=Path('/tmp/test_reports')
    )

    builder.build_report(
        invariants=[],
        violation_results=test_results,
        storage_changes={},
        runtime_metrics={'gas_used': 1000000},
        attack_tx_hash='0x123...'
    )
